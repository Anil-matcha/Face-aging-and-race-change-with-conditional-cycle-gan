{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cycle_gan_keras_conditional.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBVlSo6eEs58",
        "colab_type": "code",
        "outputId": "5e46eb30-8713-447f-84f0-ee301d2f8a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "'''\n",
        "!cp drive/'My Drive'/trainA.zip .\n",
        "!cp drive/'My Drive'/trainB.zip .\n",
        "!unzip -qq trainA.zip\n",
        "!unzip -qq trainB.zip\n",
        "!rm -rf data\n",
        "!mkdir data\n",
        "!mv trainA data/\n",
        "!mv trainB data/\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n!cp drive/'My Drive'/trainA.zip .\\n!cp drive/'My Drive'/trainB.zip .\\n!unzip -qq trainA.zip\\n!unzip -qq trainB.zip\\n!rm -rf data\\n!mkdir data\\n!mv trainA data/\\n!mv trainB data/\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZh4iGzLWlxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/'My Drive'/combined_data.zip .\n",
        "!unzip -qq combined_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPOgpD6-GIqb",
        "colab_type": "code",
        "outputId": "eec88f48-9911-4c3b-d3d3-3e5a9bc50cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(os.listdir(\"data/trainA\")), len(os.listdir(\"data/trainB\")), len(os.listdir(\"data/trainArace\")), len(os.listdir(\"data/trainBrace\")))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3844 1675 3354 2165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViZ4W7AHIYrS",
        "colab_type": "code",
        "outputId": "63737d11-51e0-4f1f-8de9-e01ae610161d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 62.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.16.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.3.0\n",
            "    Uninstalling scipy-1.3.0:\n",
            "      Successfully uninstalled scipy-1.3.0\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbObAppJD4bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "class DataLoader():\n",
        "    def __init__(self, dataset_name, img_res=(128, 128)):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.img_res = img_res\n",
        "\n",
        "    def load_data(self, domain, batch_size=1, is_testing=False, is_race=False):\n",
        "        if is_race:\n",
        "          path = glob('./%s/%s%s%s/*' % (self.dataset_name, \"train\", domain, \"race\"))\n",
        "          data_type = \"train\"+\"race\"+domain\n",
        "        else:\n",
        "          path = glob('./%s/%s%s/*' % (self.dataset_name, \"train\", domain))\n",
        "        #data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
        "        \n",
        "        \n",
        "        batch_images = np.random.choice(path, size=batch_size)\n",
        "        imgs = []\n",
        "        for img_path in batch_images:\n",
        "            img = self.imread(img_path)\n",
        "            if not is_testing:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "\n",
        "                if np.random.random() > 0.5:\n",
        "                    img = np.fliplr(img)\n",
        "            else:\n",
        "                img = scipy.misc.imresize(img, self.img_res)\n",
        "            imgs.append(img)\n",
        "\n",
        "        imgs = np.array(imgs)/127.5 - 1.\n",
        "\n",
        "        return imgs\n",
        "\n",
        "    def load_batch(self, batch_size=1, is_testing=False, is_race=False):\n",
        "        path_A = glob('./%s/%sA/*' % (self.dataset_name, \"train\"))\n",
        "        path_B = glob('./%s/%sB/*' % (self.dataset_name, \"train\"))\n",
        "        path_Arace = glob('./%s/%s/*' % (self.dataset_name, \"trainArace\"))  \n",
        "        path_Brace = glob('./%s/%s/*' % (self.dataset_name, \"trainBrace\")) \n",
        "        print(len(path_A), len(path_B), len(path_Arace), len(path_Brace))\n",
        "        self.n_batches = int(min(len(path_A), len(path_B), len(path_Arace), len(path_Brace)) / batch_size)\n",
        "        if is_race:\n",
        "          path_A, path_B = path_Arace, path_Brace        \n",
        "        total_samples = self.n_batches * batch_size\n",
        "\n",
        "        # Sample n_batches * batch_size from each path list so that model sees all\n",
        "        # samples from both domains\n",
        "        path_A = np.random.choice(path_A, total_samples, replace=False)\n",
        "        path_B = np.random.choice(path_B, total_samples, replace=False)\n",
        "\n",
        "        for i in range(self.n_batches-1):\n",
        "            batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
        "            batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
        "            imgs_A, imgs_B = [], []\n",
        "            for img_A, img_B in zip(batch_A, batch_B):            \n",
        "                img_A = self.imread(img_A)\n",
        "                img_B = self.imread(img_B)\n",
        "\n",
        "                img_A = scipy.misc.imresize(img_A, self.img_res)\n",
        "                img_B = scipy.misc.imresize(img_B, self.img_res)\n",
        "\n",
        "                if not is_testing and np.random.random() > 0.5:\n",
        "                        img_A = np.fliplr(img_A)\n",
        "                        img_B = np.fliplr(img_B)\n",
        "\n",
        "                imgs_A.append(img_A)\n",
        "                imgs_B.append(img_B)\n",
        "\n",
        "            imgs_A = np.array(imgs_A)/127.5 - 1.\n",
        "            imgs_B = np.array(imgs_B)/127.5 - 1.\n",
        "\n",
        "            yield imgs_A, imgs_B\n",
        "\n",
        "    def load_img(self, path):\n",
        "        img = self.imread(path)\n",
        "        img = scipy.misc.imresize(img, self.img_res)\n",
        "        img = img/127.5 - 1.\n",
        "        return img[np.newaxis, :, :, :]\n",
        "      \n",
        "    def get_img(self, img):\n",
        "        img = scipy.misc.imresize(img, self.img_res)\n",
        "        img = img/127.5 - 1.\n",
        "        return img\n",
        "      \n",
        "    def revert_img(self, img, new_res):\n",
        "      img = scipy.misc.imresize(img, new_res)\n",
        "      img = (img)*0.5 + 0.5\n",
        "      img = img*255\n",
        "      img = img.astype(np.float32)\n",
        "      return img \n",
        "\n",
        "    def imread(self, path):\n",
        "        return scipy.misc.imread(path, mode='RGB').astype(np.float)\n",
        "      \n",
        "def revert_img(img, new_res):\n",
        "  img = (img)*0.5 + 0.5\n",
        "  img = img*255\n",
        "  img = scipy.misc.imresize(img, new_res)\n",
        "  img = img.astype(np.float32)\n",
        "  return img       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz5TomqoEPWx",
        "colab_type": "code",
        "outputId": "e9beb823-f772-4d5c-f603-aa5bdd640877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-hkxuhevz\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-hkxuhevz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.16.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101066 sha256=a7c56fb1b02abea55a352f5a89223ab17f90434d861e5a1a4c8eb47fcb8bcac1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ph37bcow/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_rhhEvjq9ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import scipy, os\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import relu \n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import shutil, os, random\n",
        "from keras.models import load_model\n",
        "\n",
        "class CycleGAN():\n",
        "    def __init__(self):\n",
        "        # Input shape\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.condition_shape = (self.img_rows, self.img_cols, 1)        \n",
        "\n",
        "        # Configure data loader\n",
        "        self.dataset_name = 'data'\n",
        "        self.data_loader = DataLoader(dataset_name=self.dataset_name,\n",
        "                                      img_res=(self.img_rows, self.img_cols))\n",
        "\n",
        "\n",
        "        # Calculate output shape of D (PatchGAN)\n",
        "        patch = int(self.img_rows / 2**4)\n",
        "        self.disc_patch = (patch, patch, 1)\n",
        "\n",
        "        # Number of filters in the first layer of G and D\n",
        "        self.gf = 64\n",
        "        self.df = 64\n",
        "\n",
        "        # Loss weights\n",
        "        self.lambda_cycle = 0.1                   # Cycle-consistency loss\n",
        "        self.lambda_id = 0.1 * self.lambda_cycle    # Identity loss\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        pdir = \"/content/drive/My Drive/keras_combined_gan/\"\n",
        "        # Build and compile the discriminators\n",
        "        if os.path.exists(pdir+\"d_A.h5\"):\n",
        "          self.d_A = self.build_discriminator()\n",
        "          #self.d_A = load_model(pdir+\"d_A.h5\", custom_objects={'InstanceNormalization':InstanceNormalization})\n",
        "          self.d_A.layers.pop(0)\n",
        "          newInput = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newOutputs = self.d_A(newInput)\n",
        "          self.d_A = Model(newInput, newOutputs)\n",
        "          self.d_A.load_weights(pdir+\"d_A.h5\")\n",
        "        else:  \n",
        "          self.d_A = self.build_discriminator()\n",
        "        self.d_A.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])\n",
        "        \n",
        "        \n",
        "        if os.path.exists(pdir+\"d_Arace.h5\"):\n",
        "          self.d_Arace = self.build_discriminator()\n",
        "          self.d_Arace.layers.pop(0)\n",
        "          newInput = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newOutputs = self.d_Arace(newInput)\n",
        "          self.d_Arace = Model(newInput, newOutputs)\n",
        "          self.d_Arace.load_weights(pdir+\"d_Arace.h5\")\n",
        "        else:  \n",
        "          self.d_Arace = self.build_discriminator()\n",
        "        self.d_Arace.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])        \n",
        "        \n",
        "        \n",
        "        if os.path.exists(pdir+\"d_B.h5\"):\n",
        "          self.d_B = self.build_discriminator()\n",
        "          self.d_B.layers.pop(0)\n",
        "          newInput = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newOutputs = self.d_B(newInput)\n",
        "          self.d_B = Model(newInput, newOutputs)\n",
        "          self.d_B.load_weights(pdir+\"d_B.h5\")\n",
        "        else:  \n",
        "          self.d_B = self.build_discriminator()\n",
        "        self.d_B.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])\n",
        "        \n",
        "        if os.path.exists(pdir+\"d_Brace.h5\"):\n",
        "          self.d_Brace = self.build_discriminator()\n",
        "          self.d_Brace.layers.pop(0)\n",
        "          newInput = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newOutputs = self.d_Brace(newInput)\n",
        "          self.d_Brace = Model(newInput, newOutputs)\n",
        "          self.d_Brace.load_weights(pdir+\"d_Brace.h5\")\n",
        "        else:  \n",
        "          self.d_Brace = self.build_discriminator()\n",
        "        self.d_Brace.compile(loss='mse',\n",
        "          optimizer=optimizer,\n",
        "          metrics=['accuracy'])        \n",
        "        \n",
        "\n",
        "        #-------------------------\n",
        "        # Construct Computational\n",
        "        #   Graph of Generators\n",
        "        #-------------------------\n",
        "\n",
        "        # Build the generators\n",
        "        if os.path.exists(pdir+\"g_AB.h5\"):\n",
        "          self.g_AB = self.build_generator()\n",
        "          #self.g_AB = load_model(pdir+\"g_AB.h5\", custom_objects={'InstanceNormalization':InstanceNormalization})\n",
        "          self.g_AB.layers.pop(0)\n",
        "          self.g_AB.layers.pop(0)\n",
        "          newInput1 = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newInput2 = Input(shape=self.condition_shape)\n",
        "          newOutputs = self.g_AB([newInput1, newInput2])\n",
        "          self.g_AB = Model([newInput1, newInput2], newOutputs)\n",
        "          self.g_AB.load_weights(pdir+\"g_AB.h5\")\n",
        "        else:  \n",
        "          self.g_AB = self.build_generator()\n",
        "        if os.path.exists(pdir+\"g_BA.h5\"):  \n",
        "          self.g_BA = self.build_generator()\n",
        "          #self.g_BA = load_model(pdir+\"g_BA.h5\", custom_objects={'InstanceNormalization':InstanceNormalization})\n",
        "          self.g_BA.layers.pop(0)\n",
        "          self.g_BA.layers.pop(0)\n",
        "          newInput1 = Input(shape=self.img_shape)    # let us say this new InputLayer\n",
        "          newInput2 = Input(shape=self.condition_shape)\n",
        "          newOutputs = self.g_BA([newInput1, newInput2])\n",
        "          self.g_BA = Model([newInput1, newInput2], newOutputs)\n",
        "          self.g_BA.load_weights(pdir+\"g_BA.h5\")\n",
        "        else:  \n",
        "          self.g_BA = self.build_generator()\n",
        "\n",
        "        # Input images from both domains\n",
        "        img_A = Input(shape=self.img_shape)\n",
        "        img_B = Input(shape=self.img_shape)\n",
        "        label = Input(shape=self.condition_shape) \n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB([img_A, label])\n",
        "        fake_A = self.g_BA([img_B, label])\n",
        "        # Translate images back to original domain\n",
        "        reconstr_A = self.g_BA([fake_B, label])\n",
        "        reconstr_B = self.g_AB([fake_A, label])\n",
        "        # Identity mapping of images\n",
        "        img_A_id = self.g_BA([img_A, label])\n",
        "        img_B_id = self.g_AB([img_B, label])\n",
        "\n",
        "        # For the combined model we will only train the generators\n",
        "        self.d_A.trainable = False\n",
        "        self.d_B.trainable = False\n",
        "        self.d_Arace.trainable = False\n",
        "        self.d_Brace.trainable = False        \n",
        "\n",
        "        # Discriminators determines validity of translated images\n",
        "        valid_A = self.d_A(fake_A)\n",
        "        valid_B = self.d_B(fake_B)\n",
        "        valid_Arace = self.d_Arace(fake_A)\n",
        "        valid_Brace = self.d_Brace(fake_B)        \n",
        "\n",
        "        # Combined model trains generators to fool discriminators\n",
        "        if os.path.exists(pdir+\"combined.h5\"):\n",
        "          self.combined = Model(inputs=[img_A, img_B, label],\n",
        "                                outputs=[ valid_A, valid_B,\n",
        "                                          valid_Arace, valid_Brace,\n",
        "                                        reconstr_A, reconstr_B,\n",
        "                                        img_A_id, img_B_id ])\n",
        "          #self.combined = load_model(pdir+\"combined.h5\", custom_objects={'InstanceNormalization':InstanceNormalization})\n",
        "          l1 = self.combined.layers.pop(0)\n",
        "          l2 = self.combined.layers.pop(0)\n",
        "          l3 = self.combined.layers.pop(0)\n",
        "          newInput1 = Input(shape=self.img_shape)\n",
        "          newInput2 = Input(shape=self.img_shape)\n",
        "          newInput3 = Input(shape=self.condition_shape)\n",
        "          newOutputs = self.combined([newInput1, newInput2, newInput3])\n",
        "          self.combined = Model(inputs=[newInput1, newInput2, newInput3], outputs=newOutputs)\n",
        "          self.combined.load_weights(pdir+\"combined.h5\")\n",
        "        else:  \n",
        "          self.combined = Model(inputs=[img_A, img_B, label],\n",
        "                                outputs=[ valid_A, valid_B,\n",
        "                                         valid_Arace, valid_Brace,\n",
        "                                        reconstr_A, reconstr_B,\n",
        "                                        img_A_id, img_B_id ])\n",
        "        self.combined.compile(loss=['mse', 'mse',\n",
        "                                    'mse', 'mse',\n",
        "                                  'mae', 'mae',\n",
        "                                  'mae', 'mae'],\n",
        "                            loss_weights=[  1, 1,\n",
        "                                            1, 1,\n",
        "                                          self.lambda_cycle, self.lambda_cycle,\n",
        "                                          self.lambda_id, self.lambda_id ],\n",
        "                            optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "        \"\"\"Resnet Generator\"\"\"\n",
        "\n",
        "        def conv2d(layer_input, filters=16, strides=1, name=None, f_size=4):\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same', name=name)(layer_input)\n",
        "            d = InstanceNormalization(name=name+\"_bn\")(d)\n",
        "            d = Activation('relu')(d)\n",
        "            return d\n",
        "          \n",
        "        def residual(layer_input, filters=16, strides=1, name=None, f_size=3):\n",
        "            d = conv2d(layer_input, filters=filters, strides=strides, name=name, f_size=f_size)\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=strides, padding='same', name=name+\"_2\")(d)\n",
        "            d = InstanceNormalization(name=name+\"_bn2\")(d)\n",
        "            d = keras.layers.add([d, layer_input])\n",
        "            return d\n",
        "\n",
        "        def conv2d_transpose(layer_input, filters=16, strides=1, name=None, f_size=4):\n",
        "            u = Conv2DTranspose(filters, strides=strides, name=name, kernel_size=f_size, padding='same')(layer_input)\n",
        "            u = InstanceNormalization(name=name+\"_bn\")(u)\n",
        "            u = Activation('relu')(u)\n",
        "            return u\n",
        "\n",
        "        # Image input\n",
        "        c0 = Input(shape=self.img_shape)\n",
        "        cl = Input(shape=self.condition_shape)\n",
        "        concat_layer= Concatenate()([c0, cl])\n",
        "        c1 = conv2d(concat_layer, filters=self.gf, strides=1, name=\"g_e1\", f_size=7)\n",
        "        c2 = conv2d(c1, filters=self.gf*2, strides=2, name=\"g_e2\", f_size=3)\n",
        "        c3 = conv2d(c2, filters=self.gf*4, strides=2, name=\"g_e3\", f_size=3)\n",
        "        \n",
        "        r1 = residual(c3, filters=self.gf*4, name='g_r1')\n",
        "        r2 = residual(r1, self.gf*4, name='g_r2')\n",
        "        r3 = residual(r2, self.gf*4, name='g_r3')\n",
        "        r4 = residual(r3, self.gf*4, name='g_r4')\n",
        "        r5 = residual(r4, self.gf*4, name='g_r5')\n",
        "        r6 = residual(r5, self.gf*4, name='g_r6')\n",
        "        r7 = residual(r6, self.gf*4, name='g_r7')\n",
        "        r8 = residual(r7, self.gf*4, name='g_r8')\n",
        "        r9 = residual(r8, self.gf*4, name='g_r9')\n",
        "        \n",
        "        d1 = conv2d_transpose(r9, filters=self.gf*2, f_size=3, strides=2, name='g_d1_dc')\n",
        "        d2 = conv2d_transpose(d1, filters=self.gf, f_size=3, strides=2, name='g_d2_dc')\n",
        "        \n",
        "        output_img = Conv2D(self.channels, kernel_size=7, strides=1, padding='same', activation='tanh')(d2)\n",
        "\n",
        "        return Model(inputs=[c0, cl], outputs=[output_img])\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        def d_layer(layer_input, filters, f_size=4, normalization=True):\n",
        "            \"\"\"Discriminator layer\"\"\"\n",
        "            d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
        "            d = LeakyReLU(alpha=0.2)(d)\n",
        "            if normalization:\n",
        "                d = InstanceNormalization()(d)\n",
        "            return d\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "\n",
        "        d1 = d_layer(img, self.df, normalization=False)\n",
        "        d2 = d_layer(d1, self.df*2)\n",
        "        d3 = d_layer(d2, self.df*4)\n",
        "        d4 = d_layer(d3, self.df*8)\n",
        "\n",
        "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=1, sample_interval=50):\n",
        "\n",
        "        start_time = datetime.datetime.now()\n",
        "\n",
        "        # Adversarial loss ground truths\n",
        "        valid = np.ones((batch_size,) + self.disc_patch)\n",
        "        fake = np.zeros((batch_size,) + self.disc_patch)\n",
        "        case1 = np.ones(self.condition_shape)\n",
        "        case2 = np.zeros(self.condition_shape)        \n",
        "        for epoch in range(epochs):\n",
        "            race_data = self.data_loader.load_batch(batch_size, is_race=True)\n",
        "            for batch_i, (imgs_A, imgs_B) in enumerate(self.data_loader.load_batch(batch_size)):\n",
        "\n",
        "                # ----------------------\n",
        "                #  Train Discriminators\n",
        "                # ----------------------\n",
        "\n",
        "                # Translate images to opposite domain            \n",
        "                case1stack = np.array([case1]*len(imgs_A))\n",
        "                fake_B = self.g_AB.predict([imgs_A, case1stack])\n",
        "                fake_A = self.g_BA.predict([imgs_B, case1stack])\n",
        "\n",
        "                # Train the discriminators (original images = real / translated = Fake)\n",
        "                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)               \n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)                \n",
        "                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)                \n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                # Total disciminator loss\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "                validA = self.d_Arace.predict(imgs_A)\n",
        "                validB = self.d_Brace.predict(imgs_B)                \n",
        "                # ------------------\n",
        "                #  Train Generators\n",
        "                # ------------------\n",
        "\n",
        "                # Train the generators\n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B, case1stack],\n",
        "                                                        [valid, valid,\n",
        "                                                         validA, validB,\n",
        "                                                        imgs_A, imgs_B,\n",
        "                                                        imgs_A, imgs_B])                                          \n",
        "                \n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "                if batch_i%50==0:\n",
        "                  # Plot the progress\n",
        "                  print (\"[Age Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f]  time: %s \" \\\n",
        "                                                                          % ( epoch, epochs,\n",
        "                                                                              batch_i, self.data_loader.n_batches,\n",
        "                                                                              d_loss[0], 100*d_loss[1],\n",
        "                                                                              g_loss[0],\n",
        "                                                                              np.mean(g_loss[1:3]),\n",
        "                                                                              np.mean(g_loss[3:5]),\n",
        "                                                                              np.mean(g_loss[5:6]),\n",
        "                                                                              elapsed_time))  \n",
        "                  \n",
        "                imgs_A, imgs_B = next(race_data)\n",
        "                case2stack = np.array([case2]*len(imgs_A))                   \n",
        "                fake_B = self.g_AB.predict([imgs_A, case2stack])\n",
        "                fake_A = self.g_BA.predict([imgs_B, case2stack])\n",
        "\n",
        "                # Train the discriminators (original images = real / translated = Fake)\n",
        "                dA_loss_real = self.d_Arace.train_on_batch(imgs_A, valid)\n",
        "                dA_loss_fake = self.d_Arace.train_on_batch(fake_A, fake)               \n",
        "                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)\n",
        "\n",
        "                dB_loss_real = self.d_Brace.train_on_batch(imgs_B, valid)                \n",
        "                dB_loss_fake = self.d_Brace.train_on_batch(fake_B, fake)                \n",
        "                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)\n",
        "\n",
        "                # Total disciminator loss\n",
        "                d_loss = 0.5 * np.add(dA_loss, dB_loss)\n",
        "\n",
        "                validA = self.d_A.predict(imgs_A)\n",
        "                validB = self.d_B.predict(imgs_B)                \n",
        "                # ------------------\n",
        "                #  Train Generators\n",
        "                # ------------------\n",
        "\n",
        "                # Train the generators\n",
        "                \n",
        "                g_loss = self.combined.train_on_batch([imgs_A, imgs_B, case2stack],\n",
        "                                                        [validA, validB,\n",
        "                                                         valid, valid,\n",
        "                                                        imgs_A, imgs_B,\n",
        "                                                        imgs_A, imgs_B])                  \n",
        "                \n",
        "\n",
        "                elapsed_time = datetime.datetime.now() - start_time\n",
        "                if batch_i%50==0:\n",
        "                  # Plot the progress\n",
        "                  # \n",
        "                  print (\"[Race Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %05f, adv: %05f, recon: %05f, id: %05f] time: %s \" \\\n",
        "                                                                        % ( epoch, epochs,\n",
        "                                                                            batch_i, self.data_loader.n_batches,\n",
        "                                                                            d_loss[0], 100*d_loss[1],\n",
        "                                                                            g_loss[0],\n",
        "                                                                            np.mean(g_loss[1:3]),\n",
        "                                                                            np.mean(g_loss[3:5]),\n",
        "                                                                            np.mean(g_loss[5:6]),\n",
        "                                                                            elapsed_time))\n",
        "                                                        \n",
        "                                                                              \n",
        "                # If at save interval => save generated image samples\n",
        "                if batch_i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, batch_i)    \n",
        "                if batch_i % 200 == 0:    \n",
        "                  cdir = \"/content/drive/My Drive/keras_combined_gan/\"\n",
        "                  odir = \"/content/drive/My Drive/keras_combined_gan_old/\"                  \n",
        "                  fmx = os.listdir(cdir)\n",
        "                  for fx in fmx: \n",
        "                    shutil.copy(cdir+fx, odir+fx)\n",
        "                  self.d_A.save_weights(cdir+\"d_A.h5\")\n",
        "                  self.d_B.save_weights(cdir+\"d_B.h5\")\n",
        "                  self.d_A.save_weights(cdir+\"d_Arace.h5\")\n",
        "                  self.d_B.save_weights(cdir+\"d_Brace.h5\")                  \n",
        "                  self.g_AB.save_weights(cdir+\"g_AB.h5\")\n",
        "                  self.g_BA.save_weights(cdir+\"g_BA.h5\")\n",
        "                  self.combined.save_weights(cdir+\"combined.h5\")\n",
        "            \n",
        "    def sample_images(self, epoch, batch_i):\n",
        "        os.makedirs('images/%s' % self.dataset_name, exist_ok=True)\n",
        "        r, c = 2, 3\n",
        "\n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=False)\n",
        "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=False)\n",
        "\n",
        "        # Demo (for GIF)\n",
        "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        case1 = np.ones(self.condition_shape)\n",
        "        case2 = np.zeros(self.condition_shape)\n",
        "        case1stack = np.array([case1]*len(imgs_A))\n",
        "        case2stack = np.array([case2]*len(imgs_A))  \n",
        "        fake_B = self.g_AB.predict([imgs_A, case1stack])\n",
        "        fake_A = self.g_BA.predict([imgs_B, case1stack])\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict([fake_B, case1stack])\n",
        "        reconstr_B = self.g_AB.predict([fake_A, case1stack])\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/%s/%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
        "        plt.close()\n",
        "        \n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=False, is_race=True)\n",
        "        imgs_B = self.data_loader.load_data(domain=\"B\", batch_size=1, is_testing=False, is_race=True)\n",
        "\n",
        "        # Demo (for GIF)\n",
        "        #imgs_A = self.data_loader.load_img('datasets/apple2orange/testA/n07740461_1541.jpg')\n",
        "        #imgs_B = self.data_loader.load_img('datasets/apple2orange/testB/n07749192_4241.jpg')\n",
        "\n",
        "        # Translate images to the other domain\n",
        "        fake_B = self.g_AB.predict([imgs_A, case2stack])\n",
        "        fake_A = self.g_BA.predict([imgs_B, case2stack])\n",
        "        # Translate back to original domain\n",
        "        reconstr_A = self.g_BA.predict([fake_B, case2stack])\n",
        "        reconstr_B = self.g_AB.predict([fake_A, case2stack])\n",
        "\n",
        "        gen_imgs = np.concatenate([imgs_A, fake_B, reconstr_A, imgs_B, fake_A, reconstr_B])\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        titles = ['Original', 'Translated', 'Reconstructed']\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt])\n",
        "                axs[i, j].set_title(titles[j])\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/%s/race%d_%d.png\" % (self.dataset_name, epoch, batch_i))\n",
        "        plt.close()        \n",
        "\n",
        "    def run_20_to_50(self, image):\n",
        "        imgs_A = self.data_loader.load_data(domain=\"A\", batch_size=1, is_testing=True)        \n",
        "        fake_B = self.g_AB.predict(imgs_A)\n",
        "\n",
        "gan = CycleGAN()\n",
        "gan.train(epochs=200, batch_size=8, sample_interval=40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cabSHlNwX0sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm images/data/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At1nEuOEgeUZ",
        "colab_type": "code",
        "outputId": "74f38898-0e6f-4fb7-80ff-2460cee278f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!wget https://github.com/spmallick/learnopencv/raw/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/opencv_face_detector.pbtxt  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-02 02:01:59--  https://github.com/spmallick/learnopencv/raw/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/spmallick/learnopencv/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb [following]\n",
            "--2019-08-02 02:02:00--  https://raw.githubusercontent.com/spmallick/learnopencv/master/FaceDetectionComparison/models/opencv_face_detector_uint8.pb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2727750 (2.6M) [application/octet-stream]\n",
            "Saving to: ‘opencv_face_detector_uint8.pb’\n",
            "\n",
            "opencv_face_detecto 100%[===================>]   2.60M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-08-02 02:02:01 (57.2 MB/s) - ‘opencv_face_detector_uint8.pb’ saved [2727750/2727750]\n",
            "\n",
            "--2019-08-02 02:02:03--  https://raw.githubusercontent.com/opencv/opencv_extra/master/testdata/dnn/opencv_face_detector.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34912 (34K) [text/plain]\n",
            "Saving to: ‘opencv_face_detector.pbtxt’\n",
            "\n",
            "opencv_face_detecto 100%[===================>]  34.09K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2019-08-02 02:02:03 (6.41 MB/s) - ‘opencv_face_detector.pbtxt’ saved [34912/34912]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG38tXnqGhpw",
        "colab_type": "code",
        "outputId": "6e709270-16ec-4f83-d69f-e575ab494f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://statics.sportskeeda.com/editor/2018/09/4c606-1536825356-800.jpg \n",
        "!mv 4c606-1536825356-800.jpg big3.jpg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-01 21:34:20--  https://statics.sportskeeda.com/editor/2018/09/4c606-1536825356-800.jpg\n",
            "Resolving statics.sportskeeda.com (statics.sportskeeda.com)... 13.32.123.109, 13.32.123.74, 13.32.123.118, ...\n",
            "Connecting to statics.sportskeeda.com (statics.sportskeeda.com)|13.32.123.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60556 (59K) [image/jpeg]\n",
            "Saving to: ‘4c606-1536825356-800.jpg.1’\n",
            "\n",
            "\r          4c606-153   0%[                    ]       0  --.-KB/s               \r4c606-1536825356-80 100%[===================>]  59.14K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2019-08-01 21:34:20 (7.41 MB/s) - ‘4c606-1536825356-800.jpg.1’ saved [60556/60556]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ska6Ph3g32i",
        "colab_type": "code",
        "outputId": "be885c9c-a573-4118-e760-e519f6f821c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import cv2\n",
        "%matplotlib inline \n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "def detectFaceOpenCVDnn(net, frame):\n",
        "    frameOpencvDnn = frame.copy()\n",
        "    frameHeight = frameOpencvDnn.shape[0]\n",
        "    frameWidth = frameOpencvDnn.shape[1]\n",
        "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (frameHeight, frameWidth), [104, 117, 123], False, False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward()\n",
        "    bboxes = []\n",
        "    for i in range(detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence > conf_threshold:\n",
        "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
        "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
        "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
        "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
        "            bboxes.append([x1, y1, x2, y2])\n",
        "            if not(x1<30 or y1<30 or x2>frameWidth-30 or y2>frameHeight-30):\n",
        "              y1, y2 = y1-20, y2+20\n",
        "              x1, x2 = x1-20, x2+20\n",
        "            else:\n",
        "              continue\n",
        "            print(y2, y1, x2, x1)  \n",
        "            crop_img = frameOpencvDnn[y1:y2, x1:x2]\n",
        "            crop_img = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB).astype(\"float32\")\n",
        "            cv2.imwrite(\"cropped\"+str(i)+\".jpg\", crop_img)\n",
        "            inp = np.array([gan.data_loader.get_img(crop_img)])\n",
        "            old_img = gan.g_AB.predict(inp)\n",
        "            print(y2-y1, x2-x1, old_img.shape)\n",
        "            new_img = revert_img(old_img[0], (y2-y1, x2-x1))\n",
        "            print(new_img.shape)\n",
        "            new_img = cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR).astype(\"float32\")\n",
        "            print(\"bdcst\", y2-y1, x2-x1, new_img.shape)\n",
        "            frameOpencvDnn[y1:y2, x1:x2] = new_img\n",
        "            scipy.misc.imsave(\"old\"+str(i)+\".jpg\", new_img)\n",
        "    return frameOpencvDnn, bboxes\n",
        "  \n",
        "conf_threshold = 0.95\n",
        "modelFile = \"opencv_face_detector_uint8.pb\"\n",
        "configFile = \"opencv_face_detector.pbtxt\"\n",
        "net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
        "frame = cv2.imread(\"group.jpg\")\n",
        "outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,frame)\n",
        "cv2.imwrite(\"group_faces.jpg\", outOpencvDnn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391 210 193 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "181 157 (1, 256, 256, 3)\n",
            "(181, 157, 3)\n",
            "bdcst 181 157 (181, 157, 3)\n",
            "203 23 256 114\n",
            "180 142 (1, 256, 256, 3)\n",
            "(180, 142, 3)\n",
            "bdcst 180 142 (180, 142, 3)\n",
            "377 180 385 238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``skimage.transform.resize`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: `imsave` is deprecated!\n",
            "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imwrite`` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "197 147 (1, 256, 256, 3)\n",
            "(197, 147, 3)\n",
            "bdcst 197 147 (197, 147, 3)\n",
            "515 240 584 358\n",
            "275 226 (1, 256, 256, 3)\n",
            "(275, 226, 3)\n",
            "bdcst 275 226 (275, 226, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}